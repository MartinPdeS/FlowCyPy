{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "c931628a-cd89-4ed1-85ba-70abc9c3e79f",
   "metadata": {},
   "source": [
    "Imports\n",
    "-------"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "f3f5a834-299d-49a6-a00e-53048404a471",
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import List, Tuple, Union\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras import layers, models\n",
    "import sklearn.model_selection as sk\n",
    "from tensorflow.keras.utils import to_categorical"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3c920950-8c3b-4ae4-b393-2b6055a4b18e",
   "metadata": {},
   "source": [
    "Data generation\n",
    "---------------"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "669b5634-3338-47fe-9fb6-aacd28241e6d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_gaussian(amplitude, x, center, width):\n",
    "    return amplitude * np.exp(-((x - center) ** 2) / (2 * width ** 2))\n",
    "\n",
    "def generate_gaussian_data(\n",
    "    num_samples, \n",
    "    input_length, \n",
    "    num_gaussian=(1, 5), \n",
    "    amplitude_range=(1, 5), \n",
    "    center_range=(32, 96), \n",
    "    width_range=(5, 20), \n",
    "    noise_amplitude=0.0):\n",
    "    \"\"\"\n",
    "    Generate a dataset of Gaussian curves, with a variable or fixed number of peaks per slice,\n",
    "    and optional Gaussian noise.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    num_samples : int\n",
    "        Number of slices to generate.\n",
    "    input_length : int\n",
    "        Length of each slice.\n",
    "    num_gaussian : int or tuple of int\n",
    "        If int, fixed number of Gaussian peaks per slice.\n",
    "        If tuple, (min_peaks, max_peaks), a random number of peaks per slice within this range.\n",
    "    amplitude_range : tuple of float\n",
    "        Range of amplitudes for the Gaussian peaks.\n",
    "    center_range : tuple of int\n",
    "        Range of center positions for the Gaussian peaks.\n",
    "    width_range : tuple of float\n",
    "        Range of standard deviations (widths) for the Gaussian peaks.\n",
    "    noise_amplitude : float\n",
    "        Standard deviation of the Gaussian noise added to each slice.\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    X_train : numpy.ndarray\n",
    "        Array of slices with Gaussian peaks and added noise, shape (num_samples, input_length, 1).\n",
    "    y_train : numpy.ndarray\n",
    "        Array of maximum values for each peak in every slice, shape (num_samples, max_peaks).\n",
    "    num_peaks : numpy.ndarray\n",
    "        Array with the number of peaks in each slice, shape (num_samples,).\n",
    "    peak_positions : numpy.ndarray\n",
    "        Array with the positions of peaks in each slice, shape (num_samples, max_peaks).\n",
    "        Unused entries are filled with zeros.\n",
    "    \"\"\"\n",
    "    if isinstance(num_gaussian, tuple):\n",
    "        min_peaks, max_peaks = num_gaussian\n",
    "    else:\n",
    "        min_peaks = max_peaks = num_gaussian\n",
    "\n",
    "    max_peaks = max(max_peaks, 1)  # Ensure at least one peak\n",
    "    X_train = np.zeros((num_samples, input_length, 1))\n",
    "    amplitudes_array = np.zeros((num_samples, max_peaks))  # Store amplitudes of peaks\n",
    "    num_peaks_array = np.zeros(num_samples, dtype=int)  # Store the number of peaks per slice\n",
    "    peak_positions_array = np.zeros((num_samples, max_peaks))  # Store the positions of peaks\n",
    "    peak_widths_array = np.zeros((num_samples, max_peaks))\n",
    "        \n",
    "    x = np.linspace(0, input_length - 1, input_length)\n",
    "\n",
    "    for i in range(num_samples):\n",
    "        slice_curve = np.zeros(input_length)  # Initialize the slice\n",
    "\n",
    "        # Determine the number of peaks for this slice\n",
    "        num_peaks_array[i] = np.random.randint(min_peaks, max_peaks + 1)\n",
    "        peak_amplitudes = []\n",
    "        peak_centers = []\n",
    "        peak_widths = []\n",
    "\n",
    "        for _ in range(num_peaks_array[i]):\n",
    "            amplitude = np.random.uniform(*amplitude_range)\n",
    "            center = np.random.uniform(*center_range)\n",
    "            width = np.random.uniform(*width_range)\n",
    "\n",
    "            # Gaussian curve: y = A * exp(-((x - center)^2) / (2 * width^2))\n",
    "            slice_curve += get_gaussian(amplitude, x, center, width)  # Add the Gaussian peak to the slice\n",
    "            peak_amplitudes.append(amplitude)\n",
    "            peak_centers.append(center)\n",
    "            peak_widths.append(width)\n",
    "\n",
    "        # Add Gaussian noise to the slice\n",
    "        noise = np.random.normal(0, noise_amplitude, input_length)\n",
    "        slice_curve += noise\n",
    "\n",
    "        # Update the arrays\n",
    "        X_train[i, :, 0] = slice_curve\n",
    "        amplitudes_array[i, :num_peaks_array[i]] = sorted(peak_amplitudes, reverse=True)\n",
    "        peak_positions_array[i, :num_peaks_array[i]] = peak_centers\n",
    "        peak_widths_array[i, :num_peaks_array[i]] = peak_widths\n",
    "\n",
    "    return X_train, amplitudes_array, num_peaks_array, peak_positions_array, peak_widths_array\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5a506539-5593-4bee-ae8e-cd26a41ab6f1",
   "metadata": {},
   "source": [
    "Model generation\n",
    "----------------"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "cd8ec709-70a2-410c-96d9-322965230d85",
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_model(input_length, max_number_of_peaks):\n",
    "    \"\"\"\n",
    "    Build a model that predicts both the maximum value and the position of the maximum value\n",
    "    from the input signal.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    input_length : int\n",
    "        Length of the input signal (e.g., 128).\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    tensorflow.keras.Model\n",
    "        The constructed Keras model.\n",
    "    \"\"\"\n",
    "    input_layer = layers.Input(shape=(input_length, 1))\n",
    "\n",
    "    # Feature extraction\n",
    "    x = layers.Conv1D(filters=32, kernel_size=3, activation=\"relu\", padding=\"same\")(input_layer)\n",
    "    x = layers.BatchNormalization()(x)\n",
    "    x = layers.Conv1D(filters=64, kernel_size=3, activation=\"relu\", padding=\"same\")(x)\n",
    "    x = layers.BatchNormalization()(x)\n",
    "\n",
    "    # Attention mechanism\n",
    "    # attention = layers.Attention()([x, x])\n",
    "    # query = layers.Dense(64)(x)  # Learnable query\n",
    "    # key = layers.Dense(64)(x)    # Keys\n",
    "    # value = layers.Dense(64)(x)  # Values\n",
    "    attention = layers.Attention()([x, x])\n",
    "\n",
    "    x = layers.GlobalAveragePooling1D()(attention)\n",
    "    \n",
    "\n",
    "    # Flatten and dense layers\n",
    "    x = layers.Flatten()(x)\n",
    "    x = layers.Dense(64, activation=\"relu\")(x)\n",
    "    x = layers.Dense(32, activation=\"relu\")(x)\n",
    "\n",
    "    # Output layer\n",
    "    num_peaks_output = layers.Dense(max_number_of_peaks + 1, activation=\"softmax\", name=\"num_peaks\")(x)\n",
    "\n",
    "    return models.Model(inputs=input_layer, outputs=num_peaks_output)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6125c1fa-df63-44a8-a03d-541e7f9365b8",
   "metadata": {},
   "source": [
    "Utils\n",
    "-----"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 176,
   "id": "c1b7fa04-3b4e-48fb-b606-846965e39db4",
   "metadata": {},
   "outputs": [],
   "source": [
    "from itertools import islice\n",
    "\n",
    "def batched(iterable, n):\n",
    "    # batched('ABCDEFG', 3) → ABC DEF G\n",
    "    if n < 1:\n",
    "        raise ValueError('n must be at least one')\n",
    "    iterator = iter(iterable)\n",
    "    while batch := tuple(islice(iterator, n)):\n",
    "        yield batch\n",
    "\n",
    "        \n",
    "def dataset_split(test_size, random_state, max_number_of_peaks, **kwargs):\n",
    "\n",
    "    values = list(kwargs.values())\n",
    "\n",
    "    splitted = sk.train_test_split(*values, test_size=0.2, random_state=42)\n",
    "\n",
    "    output = {\n",
    "        'train': dict(), 'test': dict()\n",
    "    }\n",
    "    \n",
    "    for (k, v), (train_data, test_data) in zip(kwargs.items(), batched(splitted, 2)):\n",
    "        if k == 'num_peaks':\n",
    "            train_data =  to_categorical(train_data, max_number_of_peaks + 1)\n",
    "            test_data =  to_categorical(test_data, max_number_of_peaks + 1)\n",
    "        \n",
    "        output['train'][k] = train_data\n",
    "        output['test'][k] = test_data\n",
    "\n",
    "    return output\n",
    "\n",
    "\n",
    "def plot_model_performance(history, model, validation_data, num_examples=5):\n",
    "    \"\"\"\n",
    "    Plot training history and visualize validation cases for a trained model.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    history : tensorflow.keras.callbacks.History\n",
    "        The training history object from model.fit().\n",
    "    model : tensorflow.keras.Model\n",
    "        The trained Keras model.\n",
    "    validation_data : tuple\n",
    "        Tuple containing validation inputs and expected outputs:\n",
    "        (X_val, y_val).\n",
    "    num_examples : int, optional\n",
    "        Number of validation cases to visualize. Default is 5.\n",
    "    \"\"\"\n",
    "    plt.close('all')\n",
    "    # Visualize validation cases in subplots\n",
    "    num_rows = (num_examples + 1)\n",
    "\n",
    "    fig, axes = plt.subplots(num_rows, 1, figsize=(12, num_rows * 3))\n",
    "\n",
    "    ax = axes[0]\n",
    "    twin_ax = ax.twinx()\n",
    "    ax.plot(history.history['loss'], label='Training Loss', color='C0')\n",
    "    twin_ax.plot(history.history['val_accuracy'], color='C1', label='Validation Accuracy')\n",
    "    ax.set_xlabel('Epochs')\n",
    "    ax.set_ylabel('Loss')\n",
    "    ax.legend()\n",
    "    twin_ax.legend()\n",
    "\n",
    "    indices = np.random.choice(len(validation_data['test']['raw']), num_examples, replace=False)\n",
    "    for ax, (idx, _) in zip(axes[1:], enumerate(indices)):\n",
    "        true_num_peaks = validation_data['test']['num_peaks'][idx]\n",
    "        true_peak_positions = validation_data['test']['positions'][idx]\n",
    "        true_peak_widths = validation_data['test']['widths'][idx]\n",
    "        true_peak_amplitudes = validation_data['test']['amplitudes'][idx]\n",
    "        \n",
    "        x = np.arange(128)\n",
    "        \n",
    "        input_signal = validation_data['test']['raw'][idx, :, 0]\n",
    "        \n",
    "        \n",
    "        predicted_num_peaks = model.predict(validation_data['test']['raw'][idx:idx + 1])[0]\n",
    "        \n",
    "        ax.plot(input_signal, label=f\"GD: {np.argmax(true_num_peaks)} -- Pred: {np.argmax(predicted_num_peaks)}\")\n",
    "\n",
    "        for position, amplitude, width in zip(true_peak_positions, true_peak_amplitudes, true_peak_widths):\n",
    "            if position !=0:\n",
    "                ax.plot(x, get_gaussian(amplitude, x, position, width), linestyle='--', color='black')\n",
    "                ax.axvline(position, color='red')\n",
    "\n",
    "        ax.legend()\n",
    "\n",
    "    plt.tight_layout()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1e5070a0-7761-406b-a41a-328af0172b0c",
   "metadata": {},
   "source": [
    "Script\n",
    "------"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 178,
   "id": "44c74254-7884-41e6-9f80-7db15060359b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/120\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 16ms/step - accuracy: 0.3502 - loss: 1.5175 - val_accuracy: 0.2000 - val_loss: 1.5332\n",
      "Epoch 2/120\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.6598 - loss: 1.0331 - val_accuracy: 0.2000 - val_loss: 1.4680\n",
      "Epoch 3/120\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.7252 - loss: 0.7105 - val_accuracy: 0.2000 - val_loss: 1.4226\n",
      "Epoch 4/120\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.7936 - loss: 0.5572 - val_accuracy: 0.2500 - val_loss: 1.3994\n",
      "Epoch 5/120\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.7541 - loss: 0.5209 - val_accuracy: 0.3000 - val_loss: 1.3584\n",
      "Epoch 6/120\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.7933 - loss: 0.4544 - val_accuracy: 0.3750 - val_loss: 1.3107\n",
      "Epoch 7/120\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.8367 - loss: 0.4183 - val_accuracy: 0.4125 - val_loss: 1.2357\n",
      "Epoch 8/120\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.8186 - loss: 0.4189 - val_accuracy: 0.4500 - val_loss: 1.1539\n",
      "Epoch 9/120\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.7910 - loss: 0.4992 - val_accuracy: 0.5125 - val_loss: 1.1113\n",
      "Epoch 10/120\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.8457 - loss: 0.3829 - val_accuracy: 0.5625 - val_loss: 1.0653\n",
      "Epoch 11/120\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.8589 - loss: 0.3571 - val_accuracy: 0.6250 - val_loss: 1.0134\n",
      "Epoch 12/120\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.8628 - loss: 0.3609 - val_accuracy: 0.6750 - val_loss: 0.9643\n",
      "Epoch 13/120\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.8297 - loss: 0.3433 - val_accuracy: 0.7375 - val_loss: 0.9310\n",
      "Epoch 14/120\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.9123 - loss: 0.2916 - val_accuracy: 0.7625 - val_loss: 0.9201\n",
      "Epoch 15/120\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.8922 - loss: 0.2750 - val_accuracy: 0.7000 - val_loss: 0.9044\n",
      "Epoch 16/120\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.8177 - loss: 0.4122 - val_accuracy: 0.7250 - val_loss: 0.8732\n",
      "Epoch 17/120\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.8165 - loss: 0.4097 - val_accuracy: 0.7500 - val_loss: 0.8622\n",
      "Epoch 18/120\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.8697 - loss: 0.3378 - val_accuracy: 0.7375 - val_loss: 0.8909\n",
      "Epoch 19/120\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.9079 - loss: 0.2694 - val_accuracy: 0.7125 - val_loss: 0.8772\n",
      "Epoch 20/120\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.8183 - loss: 0.3818 - val_accuracy: 0.6875 - val_loss: 0.7992\n",
      "Epoch 21/120\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.9004 - loss: 0.2943 - val_accuracy: 0.6750 - val_loss: 0.7588\n",
      "Epoch 22/120\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.8919 - loss: 0.2589 - val_accuracy: 0.7000 - val_loss: 0.8060\n",
      "Epoch 23/120\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.8970 - loss: 0.2782 - val_accuracy: 0.6625 - val_loss: 0.8130\n",
      "Epoch 24/120\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.8996 - loss: 0.2757 - val_accuracy: 0.6875 - val_loss: 0.7482\n",
      "Epoch 25/120\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.9114 - loss: 0.2285 - val_accuracy: 0.6750 - val_loss: 0.7223\n",
      "Epoch 26/120\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.9201 - loss: 0.2363 - val_accuracy: 0.7250 - val_loss: 0.7000\n",
      "Epoch 27/120\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.8403 - loss: 0.3774 - val_accuracy: 0.7125 - val_loss: 0.7011\n",
      "Epoch 28/120\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.9296 - loss: 0.2178 - val_accuracy: 0.7000 - val_loss: 0.6368\n",
      "Epoch 29/120\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.9085 - loss: 0.2357 - val_accuracy: 0.6750 - val_loss: 0.6544\n",
      "Epoch 30/120\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.8920 - loss: 0.2753 - val_accuracy: 0.6875 - val_loss: 0.6864\n",
      "Epoch 31/120\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.9020 - loss: 0.2317 - val_accuracy: 0.7125 - val_loss: 0.6680\n",
      "Epoch 32/120\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.9295 - loss: 0.2101 - val_accuracy: 0.7375 - val_loss: 0.6083\n",
      "Epoch 33/120\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.9480 - loss: 0.1789 - val_accuracy: 0.7500 - val_loss: 0.5656\n",
      "Epoch 34/120\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.9087 - loss: 0.2456 - val_accuracy: 0.7250 - val_loss: 0.5605\n",
      "Epoch 35/120\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.9045 - loss: 0.2191 - val_accuracy: 0.7125 - val_loss: 0.5668\n",
      "Epoch 36/120\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.9354 - loss: 0.1749 - val_accuracy: 0.7250 - val_loss: 0.5564\n",
      "Epoch 37/120\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.9456 - loss: 0.1613 - val_accuracy: 0.6875 - val_loss: 0.5714\n",
      "Epoch 38/120\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.8940 - loss: 0.2598 - val_accuracy: 0.7500 - val_loss: 0.5552\n",
      "Epoch 39/120\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.9586 - loss: 0.1593 - val_accuracy: 0.7625 - val_loss: 0.5243\n",
      "Epoch 40/120\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.9244 - loss: 0.2246 - val_accuracy: 0.7625 - val_loss: 0.4822\n",
      "Epoch 41/120\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.8709 - loss: 0.3134 - val_accuracy: 0.7375 - val_loss: 0.5458\n",
      "Epoch 42/120\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.9525 - loss: 0.1623 - val_accuracy: 0.7375 - val_loss: 0.6293\n",
      "Epoch 43/120\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.9628 - loss: 0.1364 - val_accuracy: 0.7625 - val_loss: 0.5951\n",
      "Epoch 44/120\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.9138 - loss: 0.1630 - val_accuracy: 0.7625 - val_loss: 0.5362\n",
      "Epoch 45/120\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.8814 - loss: 0.2825 - val_accuracy: 0.8125 - val_loss: 0.4713\n",
      "Epoch 46/120\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.9060 - loss: 0.2652 - val_accuracy: 0.7875 - val_loss: 0.3851\n",
      "Epoch 47/120\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.9032 - loss: 0.2449 - val_accuracy: 0.7625 - val_loss: 0.5176\n",
      "Epoch 48/120\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.9003 - loss: 0.1915 - val_accuracy: 0.8250 - val_loss: 0.3637\n",
      "Epoch 49/120\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.9150 - loss: 0.2034 - val_accuracy: 0.7750 - val_loss: 0.3911\n",
      "Epoch 50/120\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.9671 - loss: 0.1127 - val_accuracy: 0.8125 - val_loss: 0.3788\n",
      "Epoch 51/120\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.9412 - loss: 0.1498 - val_accuracy: 0.8125 - val_loss: 0.3787\n",
      "Epoch 52/120\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.9339 - loss: 0.1766 - val_accuracy: 0.7875 - val_loss: 0.4683\n",
      "Epoch 53/120\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.9009 - loss: 0.2194 - val_accuracy: 0.8125 - val_loss: 0.4110\n",
      "Epoch 54/120\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.9656 - loss: 0.1092 - val_accuracy: 0.8500 - val_loss: 0.3772\n",
      "Epoch 55/120\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.9632 - loss: 0.1202 - val_accuracy: 0.8125 - val_loss: 0.4434\n",
      "Epoch 56/120\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.9473 - loss: 0.1540 - val_accuracy: 0.7750 - val_loss: 0.5746\n",
      "Epoch 57/120\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.9100 - loss: 0.2179 - val_accuracy: 0.7750 - val_loss: 0.5136\n",
      "Epoch 58/120\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.9355 - loss: 0.1615 - val_accuracy: 0.8125 - val_loss: 0.3902\n",
      "Epoch 59/120\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.9540 - loss: 0.1618 - val_accuracy: 0.7750 - val_loss: 0.3451\n",
      "Epoch 60/120\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.9531 - loss: 0.1494 - val_accuracy: 0.8000 - val_loss: 0.3993\n",
      "Epoch 61/120\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.9559 - loss: 0.1289 - val_accuracy: 0.7750 - val_loss: 0.4216\n",
      "Epoch 62/120\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.9617 - loss: 0.1222 - val_accuracy: 0.8625 - val_loss: 0.3049\n",
      "Epoch 63/120\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.9250 - loss: 0.1544 - val_accuracy: 0.8625 - val_loss: 0.2868\n",
      "Epoch 64/120\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.9578 - loss: 0.1128 - val_accuracy: 0.8750 - val_loss: 0.2332\n",
      "Epoch 65/120\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.9445 - loss: 0.1324 - val_accuracy: 0.8625 - val_loss: 0.2750\n",
      "Epoch 66/120\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.9440 - loss: 0.1428 - val_accuracy: 0.8750 - val_loss: 0.2563\n",
      "Epoch 67/120\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.9519 - loss: 0.1260 - val_accuracy: 0.9000 - val_loss: 0.2870\n",
      "Epoch 68/120\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.8580 - loss: 0.3069 - val_accuracy: 0.7625 - val_loss: 0.4358\n",
      "Epoch 69/120\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.8752 - loss: 0.3167 - val_accuracy: 0.8250 - val_loss: 0.4266\n",
      "Epoch 70/120\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.9515 - loss: 0.1543 - val_accuracy: 0.8000 - val_loss: 0.3508\n",
      "Epoch 71/120\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.9247 - loss: 0.1759 - val_accuracy: 0.7625 - val_loss: 0.6214\n",
      "Epoch 72/120\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.9392 - loss: 0.1933 - val_accuracy: 0.8000 - val_loss: 0.4372\n",
      "Epoch 73/120\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.9597 - loss: 0.1346 - val_accuracy: 0.8500 - val_loss: 0.2629\n",
      "Epoch 74/120\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.9243 - loss: 0.1890 - val_accuracy: 0.8875 - val_loss: 0.2318\n",
      "Epoch 75/120\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.9285 - loss: 0.1720 - val_accuracy: 0.8875 - val_loss: 0.2414\n",
      "Epoch 76/120\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.9764 - loss: 0.1197 - val_accuracy: 0.9000 - val_loss: 0.2215\n",
      "Epoch 77/120\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.9158 - loss: 0.1713 - val_accuracy: 0.9250 - val_loss: 0.2064\n",
      "Epoch 78/120\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.9800 - loss: 0.0829 - val_accuracy: 0.9250 - val_loss: 0.2416\n",
      "Epoch 79/120\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.9318 - loss: 0.1432 - val_accuracy: 0.8125 - val_loss: 0.4637\n",
      "Epoch 80/120\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.9484 - loss: 0.1288 - val_accuracy: 0.8750 - val_loss: 0.3148\n",
      "Epoch 81/120\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.9605 - loss: 0.1060 - val_accuracy: 0.9250 - val_loss: 0.2487\n",
      "Epoch 82/120\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.9935 - loss: 0.0545 - val_accuracy: 0.8000 - val_loss: 0.5839\n",
      "Epoch 83/120\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.9508 - loss: 0.1330 - val_accuracy: 0.8625 - val_loss: 0.3732\n",
      "Epoch 84/120\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.9799 - loss: 0.0863 - val_accuracy: 0.8875 - val_loss: 0.2661\n",
      "Epoch 85/120\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.9367 - loss: 0.1429 - val_accuracy: 0.9250 - val_loss: 0.2648\n",
      "Epoch 86/120\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.9381 - loss: 0.1588 - val_accuracy: 0.7875 - val_loss: 0.6442\n",
      "Epoch 87/120\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.9730 - loss: 0.1035 - val_accuracy: 0.7875 - val_loss: 0.6403\n",
      "Epoch 88/120\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.9570 - loss: 0.1095 - val_accuracy: 0.7250 - val_loss: 0.9219\n",
      "Epoch 89/120\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.9916 - loss: 0.0580 - val_accuracy: 0.8125 - val_loss: 0.6751\n",
      "Epoch 90/120\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.9733 - loss: 0.0948 - val_accuracy: 0.8375 - val_loss: 0.3777\n",
      "Epoch 91/120\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.9657 - loss: 0.1071 - val_accuracy: 0.7625 - val_loss: 0.7558\n",
      "Epoch 92/120\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.9818 - loss: 0.0712 - val_accuracy: 0.7875 - val_loss: 0.6247\n",
      "Epoch 93/120\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.9538 - loss: 0.1044 - val_accuracy: 0.8375 - val_loss: 0.3739\n",
      "Epoch 94/120\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.9804 - loss: 0.0701 - val_accuracy: 0.9250 - val_loss: 0.2615\n",
      "Epoch 95/120\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.9979 - loss: 0.0487 - val_accuracy: 0.9250 - val_loss: 0.2489\n",
      "Epoch 96/120\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.9887 - loss: 0.0545 - val_accuracy: 0.9125 - val_loss: 0.2887\n",
      "Epoch 97/120\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.9695 - loss: 0.0770 - val_accuracy: 0.9250 - val_loss: 0.2912\n",
      "Epoch 98/120\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.9449 - loss: 0.1205 - val_accuracy: 0.8750 - val_loss: 0.4005\n",
      "Epoch 99/120\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.9628 - loss: 0.0912 - val_accuracy: 0.9125 - val_loss: 0.2541\n",
      "Epoch 100/120\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.9720 - loss: 0.0795 - val_accuracy: 0.9375 - val_loss: 0.2506\n",
      "Epoch 101/120\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.9816 - loss: 0.0624 - val_accuracy: 0.8750 - val_loss: 0.3467\n",
      "Epoch 102/120\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.9994 - loss: 0.0261 - val_accuracy: 0.8750 - val_loss: 0.3172\n",
      "Epoch 103/120\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.9940 - loss: 0.0585 - val_accuracy: 0.9375 - val_loss: 0.2439\n",
      "Epoch 104/120\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.9808 - loss: 0.0548 - val_accuracy: 0.8875 - val_loss: 0.3104\n",
      "Epoch 105/120\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.9884 - loss: 0.0562 - val_accuracy: 0.9250 - val_loss: 0.3242\n",
      "Epoch 106/120\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.9745 - loss: 0.0636 - val_accuracy: 0.8625 - val_loss: 0.4167\n",
      "Epoch 107/120\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.9698 - loss: 0.0725 - val_accuracy: 0.8875 - val_loss: 0.2791\n",
      "Epoch 108/120\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.9843 - loss: 0.0494 - val_accuracy: 0.9250 - val_loss: 0.2740\n",
      "Epoch 109/120\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.9844 - loss: 0.0474 - val_accuracy: 0.9250 - val_loss: 0.2872\n",
      "Epoch 110/120\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.9889 - loss: 0.0393 - val_accuracy: 0.8750 - val_loss: 0.2804\n",
      "Epoch 111/120\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.9900 - loss: 0.0349 - val_accuracy: 0.8375 - val_loss: 0.4934\n",
      "Epoch 112/120\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.9708 - loss: 0.0539 - val_accuracy: 0.8500 - val_loss: 0.4308\n",
      "Epoch 113/120\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.9925 - loss: 0.0484 - val_accuracy: 0.9000 - val_loss: 0.2894\n",
      "Epoch 114/120\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.9905 - loss: 0.0469 - val_accuracy: 0.9000 - val_loss: 0.2666\n",
      "Epoch 115/120\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.9817 - loss: 0.0679 - val_accuracy: 0.8000 - val_loss: 0.4214\n",
      "Epoch 116/120\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.9906 - loss: 0.0542 - val_accuracy: 0.8875 - val_loss: 0.2760\n",
      "Epoch 117/120\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.9612 - loss: 0.0952 - val_accuracy: 0.9125 - val_loss: 0.2635\n",
      "Epoch 118/120\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.9672 - loss: 0.0933 - val_accuracy: 0.8250 - val_loss: 0.5561\n",
      "Epoch 119/120\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.9484 - loss: 0.0957 - val_accuracy: 0.7750 - val_loss: 0.7249\n",
      "Epoch 120/120\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.9701 - loss: 0.0980 - val_accuracy: 0.7750 - val_loss: 0.7848\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 33ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step\n"
     ]
    }
   ],
   "source": [
    "# Generate data with up to 5 peaks per slice\n",
    "INPUT_LENGTH = 128\n",
    "MAX_NUMBER_OF_PEAKS = 4\n",
    "\n",
    "gaussian_slices, amplitudes, num_peaks, positions, widths = generate_gaussian_data(\n",
    "    num_samples=400,\n",
    "    input_length=INPUT_LENGTH,\n",
    "    num_gaussian=(1, max_number_of_peaks),\n",
    "    amplitude_range=(2, 5),\n",
    "    center_range=(20, 100),\n",
    "    width_range=(5, 5),\n",
    "    noise_amplitude=0.2\n",
    ")\n",
    "\n",
    "data = dataset_split(\n",
    "    raw=gaussian_slices, \n",
    "    positions=positions, \n",
    "    num_peaks=num_peaks, \n",
    "    amplitudes=amplitudes, \n",
    "    widths=widths, \n",
    "    test_size=0.2, \n",
    "    random_state=42, \n",
    "    max_number_of_peaks=MAX_NUMBER_OF_PEAKS\n",
    ")\n",
    "\n",
    "\n",
    "model = build_model(input_length=INPUT_LENGTH, max_number_of_peaks=MAX_NUMBER_OF_PEAKS)\n",
    "\n",
    "\n",
    "model.compile(\n",
    "    optimizer='adam',\n",
    "    loss={'num_peaks': 'categorical_crossentropy',},\n",
    "    metrics={'num_peaks': ['accuracy'],}\n",
    ")\n",
    "\n",
    "history = model.fit(\n",
    "    data['train']['raw'],\n",
    "    data['train']['num_peaks'],\n",
    "    validation_data=(data['test']['raw'], data['test']['num_peaks']),\n",
    "    epochs=120,\n",
    "    batch_size=32\n",
    ")\n",
    "\n",
    "%matplotlib qt\n",
    "validation_data = (slices_validation, num_peaks_validation, amplitudes_validation, positions_validation, widths_validation)\n",
    "\n",
    "plot_model_performance(\n",
    "    history=history, \n",
    "    model=model, \n",
    "    validation_data=data, \n",
    "    num_examples=5\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "df9e0b4b-3541-428f-b3b6-09616f00500e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "27414dc2-0b97-4ace-87d9-37c48b21e43e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c33dde3b-2b3f-4725-9e57-f339f395c599",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a7d7bd64-b5f4-4aca-8931-f7ae6aceff12",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f7413439-142f-4d27-a91a-eb98705bb8ac",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "328241d6-348b-4374-8f8d-3b0e148b60e1",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.11 (MyEnv)",
   "language": "python",
   "name": "python311"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
