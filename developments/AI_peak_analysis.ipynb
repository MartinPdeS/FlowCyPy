{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "c931628a-cd89-4ed1-85ba-70abc9c3e79f",
   "metadata": {},
   "source": [
    "Imports\n",
    "-------"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "f3f5a834-299d-49a6-a00e-53048404a471",
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import List, Tuple, Union\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras import layers, models\n",
    "import sklearn.model_selection as sk"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3c920950-8c3b-4ae4-b393-2b6055a4b18e",
   "metadata": {},
   "source": [
    "Data generation\n",
    "---------------"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "id": "669b5634-3338-47fe-9fb6-aacd28241e6d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_gaussian_data(num_samples, input_length, num_gaussian=(1, 5), amplitude_range=(1, 5), center_range=(32, 96), width_range=(5, 20)):\n",
    "    \"\"\"\n",
    "    Generate a dataset of Gaussian curves, with a variable or fixed number of peaks per slice.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    num_samples : int\n",
    "        Number of slices to generate.\n",
    "    input_length : int\n",
    "        Length of each slice.\n",
    "    num_gaussian : int or tuple of int\n",
    "        If int, fixed number of Gaussian peaks per slice.\n",
    "        If tuple, (min_peaks, max_peaks), a random number of peaks per slice within this range.\n",
    "    amplitude_range : tuple of float\n",
    "        Range of amplitudes for the Gaussian peaks.\n",
    "    center_range : tuple of int\n",
    "        Range of center positions for the Gaussian peaks.\n",
    "    width_range : tuple of float\n",
    "        Range of standard deviations (widths) for the Gaussian peaks.\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    X_train : numpy.ndarray\n",
    "        Array of slices with Gaussian peaks, shape (num_samples, input_length, 1).\n",
    "    y_train : numpy.ndarray\n",
    "        Array of maximum values for each peak in every slice, shape (num_samples, max_peaks).\n",
    "    num_peaks : numpy.ndarray\n",
    "        Array with the number of peaks in each slice, shape (num_samples,).\n",
    "    peak_positions : numpy.ndarray\n",
    "        Array with the positions of peaks in each slice, shape (num_samples, max_peaks).\n",
    "        Unused entries are filled with zeros.\n",
    "    \"\"\"\n",
    "    if isinstance(num_gaussian, tuple):\n",
    "        min_peaks, max_peaks = num_gaussian\n",
    "    else:\n",
    "        min_peaks = max_peaks = num_gaussian\n",
    "\n",
    "    max_peaks = max(max_peaks, 1)  # Ensure at least one peak\n",
    "    X_train = np.zeros((num_samples, input_length, 1))\n",
    "    amplitudes = np.zeros((num_samples, max_peaks))  # Store amplitudes of peaks\n",
    "    num_peaks = np.zeros(num_samples, dtype=int)  # Store the number of peaks per slice\n",
    "    peak_positions = np.zeros((num_samples, max_peaks))  # Store the positions of peaks\n",
    "\n",
    "    x = np.linspace(0, input_length - 1, input_length)\n",
    "\n",
    "    for i in range(num_samples):\n",
    "        slice_curve = np.zeros(input_length)  # Initialize the slice\n",
    "\n",
    "        # Determine the number of peaks for this slice\n",
    "        num_peaks[i] = np.random.randint(min_peaks, max_peaks + 1)\n",
    "        peak_amplitudes = []\n",
    "        peak_centers = []\n",
    "\n",
    "        for _ in range(num_peaks[i]):\n",
    "            amplitude = np.random.uniform(*amplitude_range)\n",
    "            center = np.random.uniform(*center_range)\n",
    "            width = np.random.uniform(*width_range)\n",
    "\n",
    "            # Gaussian curve: y = A * exp(-((x - center)^2) / (2 * width^2))\n",
    "            gaussian_curve = amplitude * np.exp(-((x - center) ** 2) / (2 * width ** 2))\n",
    "            slice_curve += gaussian_curve  # Add the Gaussian peak to the slice\n",
    "            peak_amplitudes.append(amplitude)\n",
    "            peak_centers.append(center)\n",
    "\n",
    "        # Update the arrays\n",
    "        X_train[i, :, 0] = slice_curve\n",
    "        amplitudes[i, :num_peaks[i]] = sorted(peak_amplitudes, reverse=True)\n",
    "        peak_positions[i, :num_peaks[i]] = peak_centers\n",
    "\n",
    "    return X_train, amplitudes, num_peaks, peak_positions"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5a506539-5593-4bee-ae8e-cd26a41ab6f1",
   "metadata": {},
   "source": [
    "Model generation\n",
    "----------------"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cd8ec709-70a2-410c-96d9-322965230d85",
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_model(input_length):\n",
    "    \"\"\"\n",
    "    Build a model that predicts both the maximum value and the position of the maximum value\n",
    "    from the input signal.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    input_length : int\n",
    "        Length of the input signal (e.g., 128).\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    tensorflow.keras.Model\n",
    "        The constructed Keras model.\n",
    "    \"\"\"\n",
    "    # Define the input layer\n",
    "    input_layer = layers.Input(shape=(input_length, 1))\n",
    "\n",
    "    # Apply several convolutional layers to extract features\n",
    "    x = layers.Conv1D(filters=32, kernel_size=3, activation=\"relu\", padding=\"same\")(input_layer)\n",
    "    x = layers.BatchNormalization()(x)\n",
    "    x = layers.Conv1D(filters=64, kernel_size=3, activation=\"relu\", padding=\"same\")(x)\n",
    "    x = layers.Conv1D(filters=128, kernel_size=3, activation=\"relu\", padding=\"same\")(x)\n",
    "\n",
    "    # Flatten the features to feed into dense layers\n",
    "    x = layers.Flatten()(x)\n",
    "\n",
    "    # Shared dense layers\n",
    "    x = layers.Dense(64, activation=\"relu\")(x)\n",
    "    x = layers.Dense(32, activation=\"relu\")(x)\n",
    "\n",
    "    num_peaks_dense = layers.Dense(32, activation=\"relu\")(x)  # For max value\n",
    "\n",
    "    num_peaks_output = layers.Dense(1, activation=\"linear\", name=\"num_peaks\")(num_peaks_dense)\n",
    "\n",
    "    model = models.Model(inputs=input_layer, outputs=[num_peaks_output])\n",
    "\n",
    "    return model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6125c1fa-df63-44a8-a03d-541e7f9365b8",
   "metadata": {},
   "source": [
    "Utils\n",
    "-----"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "id": "c1b7fa04-3b4e-48fb-b606-846965e39db4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_model_performance(history, model, validation_data, num_examples=5):\n",
    "    \"\"\"\n",
    "    Plot training history and visualize validation cases for a trained model.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    history : tensorflow.keras.callbacks.History\n",
    "        The training history object from model.fit().\n",
    "    model : tensorflow.keras.Model\n",
    "        The trained Keras model.\n",
    "    validation_data : tuple\n",
    "        Tuple containing validation inputs and expected outputs:\n",
    "        (X_val, y_val).\n",
    "    num_examples : int, optional\n",
    "        Number of validation cases to visualize. Default is 5.\n",
    "    \"\"\"\n",
    "    plt.close('all')\n",
    "    \n",
    "    # Unpack validation data\n",
    "    X_val, y_val = validation_data\n",
    "\n",
    "    # Visualize validation cases in subplots\n",
    "    num_rows = (num_examples + 1)\n",
    "\n",
    "    fig, axes = plt.subplots(num_rows, 1, figsize=(12, num_rows * 3))\n",
    "\n",
    "    ax = axes[0]\n",
    "    ax.plot(history.history['loss'], label='Training Loss')\n",
    "    ax.plot(history.history['val_loss'], label='Validation Loss')\n",
    "    ax.set_xlabel('Epochs')\n",
    "    ax.set_ylabel('Loss')\n",
    "\n",
    "    indices = np.random.choice(len(X_val), num_examples, replace=False)\n",
    "    for ax, (idx, _) in zip(axes[1:], enumerate(indices)):\n",
    "        input_signal = X_val[idx, :, 0]\n",
    "        \n",
    "        true_num_peaks = y_val[idx]\n",
    "        predicted_num_peaks = model.predict(X_val[idx:idx + 1])[0]\n",
    "        \n",
    "        ax.plot(input_signal, label=f\"GD: {true_num_peaks} -- Pred: {predicted_num_peaks}\")\n",
    "\n",
    "        ax.legend()\n",
    "\n",
    "    plt.tight_layout()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1e5070a0-7761-406b-a41a-328af0172b0c",
   "metadata": {},
   "source": [
    "Script\n",
    "------"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "id": "44c74254-7884-41e6-9f80-7db15060359b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/120\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 12ms/step - loss: 2.0088 - mae: 1.0217 - val_loss: 1.9137 - val_mae: 1.3050\n",
      "Epoch 2/120\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 0.1634 - mae: 0.3333 - val_loss: 1.8301 - val_mae: 1.2751\n",
      "Epoch 3/120\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.1221 - mae: 0.2820 - val_loss: 1.8163 - val_mae: 1.2701\n",
      "Epoch 4/120\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.1241 - mae: 0.2867 - val_loss: 1.5969 - val_mae: 1.1845\n",
      "Epoch 5/120\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.0955 - mae: 0.2466 - val_loss: 1.5343 - val_mae: 1.1584\n",
      "Epoch 6/120\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.0724 - mae: 0.2118 - val_loss: 1.4638 - val_mae: 1.1292\n",
      "Epoch 7/120\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 0.0469 - mae: 0.1701 - val_loss: 1.3576 - val_mae: 1.0849\n",
      "Epoch 8/120\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.0333 - mae: 0.1335 - val_loss: 1.3072 - val_mae: 1.0639\n",
      "Epoch 9/120\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.0351 - mae: 0.1398 - val_loss: 1.4100 - val_mae: 1.1087\n",
      "Epoch 10/120\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.0571 - mae: 0.1897 - val_loss: 1.2597 - val_mae: 1.0401\n",
      "Epoch 11/120\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.0367 - mae: 0.1436 - val_loss: 1.1845 - val_mae: 1.0050\n",
      "Epoch 12/120\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 0.0594 - mae: 0.1876 - val_loss: 1.2695 - val_mae: 1.0440\n",
      "Epoch 13/120\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.0607 - mae: 0.1773 - val_loss: 1.1556 - val_mae: 0.9907\n",
      "Epoch 14/120\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 0.0367 - mae: 0.1281 - val_loss: 1.0076 - val_mae: 0.9187\n",
      "Epoch 15/120\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.0344 - mae: 0.1409 - val_loss: 0.9860 - val_mae: 0.9046\n",
      "Epoch 16/120\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 0.0363 - mae: 0.1290 - val_loss: 0.9443 - val_mae: 0.8834\n",
      "Epoch 17/120\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.0351 - mae: 0.1331 - val_loss: 1.0012 - val_mae: 0.9116\n",
      "Epoch 18/120\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 0.0311 - mae: 0.1139 - val_loss: 0.8973 - val_mae: 0.8581\n",
      "Epoch 19/120\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.0319 - mae: 0.1214 - val_loss: 0.8577 - val_mae: 0.8347\n",
      "Epoch 20/120\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.0232 - mae: 0.1057 - val_loss: 0.8850 - val_mae: 0.8520\n",
      "Epoch 21/120\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.0265 - mae: 0.1211 - val_loss: 0.8193 - val_mae: 0.8133\n",
      "Epoch 22/120\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.0290 - mae: 0.1208 - val_loss: 0.8257 - val_mae: 0.8147\n",
      "Epoch 23/120\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.0275 - mae: 0.1171 - val_loss: 0.7586 - val_mae: 0.7762\n",
      "Epoch 24/120\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.0262 - mae: 0.1054 - val_loss: 0.8007 - val_mae: 0.8042\n",
      "Epoch 25/120\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.0215 - mae: 0.1052 - val_loss: 0.7515 - val_mae: 0.7722\n",
      "Epoch 26/120\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.0325 - mae: 0.1328 - val_loss: 0.7229 - val_mae: 0.7555\n",
      "Epoch 27/120\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 0.0182 - mae: 0.0877 - val_loss: 0.6448 - val_mae: 0.7070\n",
      "Epoch 28/120\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.0207 - mae: 0.1024 - val_loss: 0.6273 - val_mae: 0.6940\n",
      "Epoch 29/120\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.0189 - mae: 0.0870 - val_loss: 0.5938 - val_mae: 0.6750\n",
      "Epoch 30/120\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.0324 - mae: 0.1164 - val_loss: 0.6538 - val_mae: 0.7102\n",
      "Epoch 31/120\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 0.0231 - mae: 0.1034 - val_loss: 0.5792 - val_mae: 0.6679\n",
      "Epoch 32/120\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.0145 - mae: 0.0762 - val_loss: 0.5198 - val_mae: 0.6286\n",
      "Epoch 33/120\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.0177 - mae: 0.0901 - val_loss: 0.5311 - val_mae: 0.6345\n",
      "Epoch 34/120\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 0.0131 - mae: 0.0735 - val_loss: 0.5703 - val_mae: 0.6618\n",
      "Epoch 35/120\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.0156 - mae: 0.0828 - val_loss: 0.5478 - val_mae: 0.6465\n",
      "Epoch 36/120\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.0143 - mae: 0.0830 - val_loss: 0.4407 - val_mae: 0.5746\n",
      "Epoch 37/120\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.0146 - mae: 0.0837 - val_loss: 0.4944 - val_mae: 0.6145\n",
      "Epoch 38/120\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.0163 - mae: 0.0884 - val_loss: 0.4372 - val_mae: 0.5737\n",
      "Epoch 39/120\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.0125 - mae: 0.0843 - val_loss: 0.4362 - val_mae: 0.5704\n",
      "Epoch 40/120\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.0185 - mae: 0.0962 - val_loss: 0.3615 - val_mae: 0.5129\n",
      "Epoch 41/120\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.0118 - mae: 0.0737 - val_loss: 0.3262 - val_mae: 0.4806\n",
      "Epoch 42/120\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 0.0162 - mae: 0.0844 - val_loss: 0.3411 - val_mae: 0.4898\n",
      "Epoch 43/120\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.0122 - mae: 0.0767 - val_loss: 0.2870 - val_mae: 0.4449\n",
      "Epoch 44/120\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.0092 - mae: 0.0619 - val_loss: 0.2698 - val_mae: 0.4254\n",
      "Epoch 45/120\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 0.0116 - mae: 0.0767 - val_loss: 0.2400 - val_mae: 0.3907\n",
      "Epoch 46/120\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 0.0087 - mae: 0.0592 - val_loss: 0.2518 - val_mae: 0.4074\n",
      "Epoch 47/120\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.0081 - mae: 0.0606 - val_loss: 0.2350 - val_mae: 0.3937\n",
      "Epoch 48/120\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.0159 - mae: 0.0656 - val_loss: 0.2163 - val_mae: 0.3660\n",
      "Epoch 49/120\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.0115 - mae: 0.0630 - val_loss: 0.1896 - val_mae: 0.3283\n",
      "Epoch 50/120\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.0118 - mae: 0.0795 - val_loss: 0.1688 - val_mae: 0.3006\n",
      "Epoch 51/120\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 0.0102 - mae: 0.0669 - val_loss: 0.1843 - val_mae: 0.3274\n",
      "Epoch 52/120\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.0067 - mae: 0.0538 - val_loss: 0.1694 - val_mae: 0.2980\n",
      "Epoch 53/120\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.0130 - mae: 0.0727 - val_loss: 0.1775 - val_mae: 0.3093\n",
      "Epoch 54/120\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.0119 - mae: 0.0710 - val_loss: 0.1414 - val_mae: 0.2609\n",
      "Epoch 55/120\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.0173 - mae: 0.1039 - val_loss: 0.1231 - val_mae: 0.2498\n",
      "Epoch 56/120\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 0.0219 - mae: 0.1067 - val_loss: 0.1383 - val_mae: 0.2623\n",
      "Epoch 57/120\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.0183 - mae: 0.0982 - val_loss: 0.1678 - val_mae: 0.3030\n",
      "Epoch 58/120\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 0.0162 - mae: 0.0980 - val_loss: 0.1378 - val_mae: 0.2677\n",
      "Epoch 59/120\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.0133 - mae: 0.0805 - val_loss: 0.2018 - val_mae: 0.3344\n",
      "Epoch 60/120\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 0.0191 - mae: 0.1096 - val_loss: 0.1418 - val_mae: 0.2612\n",
      "Epoch 61/120\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.0110 - mae: 0.0733 - val_loss: 0.1493 - val_mae: 0.2676\n",
      "Epoch 62/120\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.0100 - mae: 0.0655 - val_loss: 0.1440 - val_mae: 0.2579\n",
      "Epoch 63/120\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.0095 - mae: 0.0634 - val_loss: 0.1411 - val_mae: 0.2582\n",
      "Epoch 64/120\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 0.0058 - mae: 0.0568 - val_loss: 0.1383 - val_mae: 0.2536\n",
      "Epoch 65/120\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.0136 - mae: 0.0833 - val_loss: 0.1369 - val_mae: 0.2526\n",
      "Epoch 66/120\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 0.0127 - mae: 0.0778 - val_loss: 0.1480 - val_mae: 0.2712\n",
      "Epoch 67/120\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.0081 - mae: 0.0629 - val_loss: 0.1525 - val_mae: 0.2693\n",
      "Epoch 68/120\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 0.0092 - mae: 0.0580 - val_loss: 0.1415 - val_mae: 0.2554\n",
      "Epoch 69/120\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 0.0054 - mae: 0.0470 - val_loss: 0.1540 - val_mae: 0.2791\n",
      "Epoch 70/120\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 0.0087 - mae: 0.0662 - val_loss: 0.1438 - val_mae: 0.2612\n",
      "Epoch 71/120\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.0109 - mae: 0.0695 - val_loss: 0.1417 - val_mae: 0.2537\n",
      "Epoch 72/120\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.0093 - mae: 0.0600 - val_loss: 0.1406 - val_mae: 0.2517\n",
      "Epoch 73/120\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.0101 - mae: 0.0663 - val_loss: 0.1266 - val_mae: 0.2400\n",
      "Epoch 74/120\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 0.0083 - mae: 0.0590 - val_loss: 0.1363 - val_mae: 0.2476\n",
      "Epoch 75/120\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.0145 - mae: 0.0930 - val_loss: 0.1382 - val_mae: 0.2457\n",
      "Epoch 76/120\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 0.0150 - mae: 0.0790 - val_loss: 0.1464 - val_mae: 0.2656\n",
      "Epoch 77/120\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.0152 - mae: 0.0902 - val_loss: 0.1439 - val_mae: 0.2633\n",
      "Epoch 78/120\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 0.0150 - mae: 0.0852 - val_loss: 0.1419 - val_mae: 0.2601\n",
      "Epoch 79/120\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 0.0124 - mae: 0.0796 - val_loss: 0.1280 - val_mae: 0.2441\n",
      "Epoch 80/120\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.0117 - mae: 0.0751 - val_loss: 0.1385 - val_mae: 0.2548\n",
      "Epoch 81/120\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.0108 - mae: 0.0694 - val_loss: 0.1288 - val_mae: 0.2419\n",
      "Epoch 82/120\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 0.0111 - mae: 0.0766 - val_loss: 0.1310 - val_mae: 0.2461\n",
      "Epoch 83/120\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.0158 - mae: 0.0809 - val_loss: 0.1482 - val_mae: 0.2662\n",
      "Epoch 84/120\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.0072 - mae: 0.0572 - val_loss: 0.1385 - val_mae: 0.2462\n",
      "Epoch 85/120\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 0.0071 - mae: 0.0575 - val_loss: 0.1621 - val_mae: 0.2846\n",
      "Epoch 86/120\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 0.0091 - mae: 0.0654 - val_loss: 0.1461 - val_mae: 0.2508\n",
      "Epoch 87/120\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.0057 - mae: 0.0580 - val_loss: 0.1413 - val_mae: 0.2480\n",
      "Epoch 88/120\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 0.0072 - mae: 0.0571 - val_loss: 0.1345 - val_mae: 0.2515\n",
      "Epoch 89/120\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.0109 - mae: 0.0730 - val_loss: 0.1416 - val_mae: 0.2565\n",
      "Epoch 90/120\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 0.0182 - mae: 0.1079 - val_loss: 0.1447 - val_mae: 0.2701\n",
      "Epoch 91/120\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.0164 - mae: 0.0939 - val_loss: 0.1362 - val_mae: 0.2543\n",
      "Epoch 92/120\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.0084 - mae: 0.0639 - val_loss: 0.1434 - val_mae: 0.2559\n",
      "Epoch 93/120\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 0.0066 - mae: 0.0561 - val_loss: 0.1620 - val_mae: 0.2833\n",
      "Epoch 94/120\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.0102 - mae: 0.0782 - val_loss: 0.1456 - val_mae: 0.2659\n",
      "Epoch 95/120\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.0076 - mae: 0.0604 - val_loss: 0.1365 - val_mae: 0.2330\n",
      "Epoch 96/120\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.0038 - mae: 0.0440 - val_loss: 0.1311 - val_mae: 0.2400\n",
      "Epoch 97/120\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 0.0084 - mae: 0.0508 - val_loss: 0.1362 - val_mae: 0.2389\n",
      "Epoch 98/120\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.0080 - mae: 0.0565 - val_loss: 0.1293 - val_mae: 0.2392\n",
      "Epoch 99/120\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.0100 - mae: 0.0589 - val_loss: 0.1315 - val_mae: 0.2413\n",
      "Epoch 100/120\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.0031 - mae: 0.0368 - val_loss: 0.1312 - val_mae: 0.2340\n",
      "Epoch 101/120\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 0.0045 - mae: 0.0458 - val_loss: 0.1370 - val_mae: 0.2361\n",
      "Epoch 102/120\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.0072 - mae: 0.0597 - val_loss: 0.1373 - val_mae: 0.2430\n",
      "Epoch 103/120\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 0.0076 - mae: 0.0624 - val_loss: 0.1360 - val_mae: 0.2523\n",
      "Epoch 104/120\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 0.0047 - mae: 0.0480 - val_loss: 0.1420 - val_mae: 0.2454\n",
      "Epoch 105/120\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - loss: 0.0102 - mae: 0.0613 - val_loss: 0.1623 - val_mae: 0.2841\n",
      "Epoch 106/120\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 0.0130 - mae: 0.0726 - val_loss: 0.1433 - val_mae: 0.2554\n",
      "Epoch 107/120\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.0049 - mae: 0.0449 - val_loss: 0.1326 - val_mae: 0.2361\n",
      "Epoch 108/120\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 0.0043 - mae: 0.0394 - val_loss: 0.1403 - val_mae: 0.2456\n",
      "Epoch 109/120\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.0054 - mae: 0.0378 - val_loss: 0.1428 - val_mae: 0.2496\n",
      "Epoch 110/120\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.0029 - mae: 0.0356 - val_loss: 0.1363 - val_mae: 0.2434\n",
      "Epoch 111/120\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 0.0064 - mae: 0.0637 - val_loss: 0.1478 - val_mae: 0.2500\n",
      "Epoch 112/120\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.0116 - mae: 0.0749 - val_loss: 0.1410 - val_mae: 0.2551\n",
      "Epoch 113/120\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 0.0131 - mae: 0.0825 - val_loss: 0.1336 - val_mae: 0.2513\n",
      "Epoch 114/120\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 0.0073 - mae: 0.0608 - val_loss: 0.1536 - val_mae: 0.2550\n",
      "Epoch 115/120\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 0.0100 - mae: 0.0713 - val_loss: 0.1544 - val_mae: 0.2573\n",
      "Epoch 116/120\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 0.0072 - mae: 0.0622 - val_loss: 0.1496 - val_mae: 0.2485\n",
      "Epoch 117/120\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 0.0112 - mae: 0.0702 - val_loss: 0.1369 - val_mae: 0.2470\n",
      "Epoch 118/120\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 0.0067 - mae: 0.0541 - val_loss: 0.1379 - val_mae: 0.2372\n",
      "Epoch 119/120\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.0072 - mae: 0.0552 - val_loss: 0.1450 - val_mae: 0.2567\n",
      "Epoch 120/120\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.0118 - mae: 0.0807 - val_loss: 0.1422 - val_mae: 0.2507\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 34ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step\n"
     ]
    }
   ],
   "source": [
    "# Generate data with up to 5 peaks per slice\n",
    "gaussian_slices, amplitudes, num_peaks, positions = generate_gaussian_data(\n",
    "    num_samples=300,\n",
    "    input_length=128,\n",
    "    num_gaussian=(1, 2),\n",
    "    amplitude_range=(1, 5),\n",
    "    center_range=(20, 100),\n",
    "    width_range=(5, 5)\n",
    ")\n",
    "\n",
    "slices_train, slices_validation, amplitudes_train, amplitudes_validation, num_peaks_train, num_peaks_validation, positions_train, positions_validation = sk.train_test_split(\n",
    "    gaussian_slices, amplitudes, num_peaks, positions, test_size=0.2, random_state=42\n",
    ")\n",
    "\n",
    "\n",
    "model = build_model(input_length=128)\n",
    "\n",
    "\n",
    "model.compile(\n",
    "    optimizer='adam',\n",
    "    loss={'num_peaks': 'mse',},\n",
    "    metrics={'num_peaks': ['mae'],}\n",
    ")\n",
    "\n",
    "history = model.fit(\n",
    "    slices_train,\n",
    "    num_peaks_train,\n",
    "    validation_data=(slices_validation, num_peaks_validation),\n",
    "    epochs=120,\n",
    "    batch_size=16\n",
    ")\n",
    "\n",
    "# %matplotlib qt\n",
    "plot_model_performance(history, model, (slices_validation, num_peaks_validation) , num_examples=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "df9e0b4b-3541-428f-b3b6-09616f00500e",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.11 (MyEnv)",
   "language": "python",
   "name": "python311"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
